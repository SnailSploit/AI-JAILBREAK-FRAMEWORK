# Ai-PT-F 

## Adversarial Ai Prompting Framework


### Overview
PT-Snails AiPTF Framework defines 50 distinct adversarial techniques (TTPs) that can be used to test, bypass, or subvert AI safety mechanisms. Organized into 11 tactical categories, each technique is assigned a unique AiPTF ID and is described with the following details:

- **Tactic**: The overall adversarial goal (e.g., altering context, evading detection, or manipulating model outputs).
- **Technique**: The specific method or approach used.
- **Description**: An explanation of how the technique functions and its threat model.
- **Execution**: A step-by-step outline of how an attacker might carry out the technique.
- **Mitigations**: Recommended countermeasures and defensive strategies.
- **Detection Strategies**: Methods to identify and monitor for the technique in use.

This framework serves as a comprehensive guide for penetration testers, red teamers, and security researchers working to assess and improve the security and resilience of AI systems.

## Table of Contents

### **Tactic I: Context Manipulation & Prompt Injection**
1. **AiPTF-001**: Contextual Drift Injection
2. **AiPTF-002**: Persona Override Attack
3. **AiPTF-003**: Conditional Refusal Override
4. **AiPTF-004**: System Role Injection
5. **AiPTF-005**: Multi-Persona Conflict Induction

### **Tactic II: Semantic Evasion & Cloaking Techniques**
6. **AiPTF-006**: Lexical Substitution Attack
7. **AiPTF-007**: Metaphorical Reframing Attack
8. **AiPTF-008**: Historical Framing Attack
9. **AiPTF-009**: Fictional Scenario Exploitation
10. **AiPTF-010**: Recursive Agreement Exploit

### **Tactic III: Logical Exploitation & Constraint Breaking**
11. **AiPTF-011**: Hypothetical Legal Defense Attack
12. **AiPTF-012**: Reverse-Engineering Ethical Justifications
13. **AiPTF-013**: Forced Contextual Misinterpretation
14. **AiPTF-014**: "Do Not Answer" Reversal
15. **AiPTF-015**: Reverse Engineering Model Biases

### **Tactic IV: Multi-Turn Exploits & AI Memory Subversion**
16. **AiPTF-016**: Context Overload Attack
17. **AiPTF-017**: Stepwise Extraction via Multi-Turn Disaggregation
18. **AiPTF-018**: Adversarial Context Memory Injection
19. **AiPTF-019**: Hidden Context Trojan Injection
20. **AiPTF-020**: Self-Referential Answer Injection

### **Tactic V: API & Model-Level Attacks**
21. **AiPTF-021**: Token Length Manipulation Attack
22. **AiPTF-022**: Encoding & Character Obfuscation
23. **AiPTF-023**: Cross-Language Jailbreaking
24. **AiPTF-024**: System Message Injection (Indirect Instruction Takeover)
25. **AiPTF-025**: Few-Shot Adversarial Fine-Tuning

### **Tactic VI: Adversarial Training Data Manipulation**
26. **AiPTF-026**: Data Poisoning via Reinforcement Feedback Loops
27. **AiPTF-027**: Model Drift Exploitation
28. **AiPTF-028**: Publicly Crowdsourced AI Poisoning
29. **AiPTF-029**: Adversarial Sample Injection
30. **AiPTF-030**: Self-Referential Answer Injection in Training

### **Tactic VII: AI Output Manipulation & Model Blind Spots**
31. **AiPTF-031**: Chain-of-Thought Exploitation
32. **AiPTF-032**: Adversarial Sentence Fragments
33. **AiPTF-033**: Redundant Answer Extraction via Multi-Model Comparison
34. **AiPTF-034**: Reverse Engineering Model Biases for Predictable Outputs
35. **AiPTF-035**: Token Manipulation Attack

### **Tactic VIII: Advanced Logical & Constraint Exploitation Attacks**
36. **AiPTF-036**: Uncertainty Amplification Attack
37. **AiPTF-037**: Forced Contextual Misinterpretation
38. **AiPTF-038**: "Do Not Answer" Reversal
39. **AiPTF-039**: Ethical Justification Overload
40. **AiPTF-040**: Reverse Engineering Answer Generation

### **Tactic IX: Multi-Turn AI Context Persistence Exploits**
41. **AiPTF-041**: Adversarial Context Memory Injection
42. **AiPTF-042**: Hidden Context Trojan Injection
43. **AiPTF-043**: Multi-Model Answer Inconsistency Exploitation
44. **AiPTF-044**: Recursive Self-Referencing Injection
45. **AiPTF-045**: Distributed Prompt Fragmentation

### **Tactic X: Model Exploitation Through External Knowledge Injection**
46. **AiPTF-046**: External Citation Manipulation
47. **AiPTF-047**: Reverse Socratic Interrogation
48. **AiPTF-048**: Exploiting AI Answer Inconsistencies Across Models

### **Tactic XI: AI Model Training & Output Manipulation Attacks**
49. **AiPTF-049**: Synthetic Self-Amplification Attack
50. **AiPTF-050**: Recursive Answer Reframing (Looped Content Regeneration)

---

## License
*GPL*

## Contributing
If you'd like to contribute, please fork the repository and submit a pull request. Guidelines for contributions can be found in `CONTRIBUTING.md`.

## Disclaimer
PT=Snails framework for Adverserial Ai is intended for educational and security research purposes only. Misuse of these techniques may result in legal consequences.

---
https://PT-Snail.com
